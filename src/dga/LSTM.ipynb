{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:18:28.754419Z",
     "start_time": "2020-08-04T06:18:24.953052Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Embedding, LSTM, Input\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from model_evaluator import Evaluator\n",
    "from model_preprocessor import Preprocessor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:18:28.759420Z",
     "start_time": "2020-08-04T06:18:28.755419Z"
    }
   },
   "outputs": [],
   "source": [
    "def lstm(max_len=73, emb_dim=32, max_vocab_len=40, W_reg=regularizers.l2(1e-4)):\n",
    "    \"\"\"LSTM model with the Keras Sequential model\"\"\"\n",
    "\n",
    "    input = Input(shape=(max_len,), dtype='int32', name='lstm_input')\n",
    "    emb = Embedding(input_dim=max_vocab_len, output_dim=emb_dim, input_length=max_len, W_regularizer=W_reg)(input)\n",
    "    emb = Dropout(0.5)(emb)\n",
    "    lstm = LSTM(128)(emb)\n",
    "    lstm = Dropout(0.5)(lstm)\n",
    "    output = Dense(21, activation='softmax', name='lstm_output')(lstm)\n",
    "    model = Model(input=[input], output=[output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:18:47.827983Z",
     "start_time": "2020-08-04T06:18:28.760420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data using model preprocessor\n",
    "x_train, x_test, y_train, y_test = Preprocessor.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T07:40:40.798470Z",
     "start_time": "2020-08-04T06:18:47.828982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\hyojong\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\hyojong\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1149965 samples, validate on 142131 samples\n",
      "Epoch 1/5\n",
      "1149965/1149965 [==============================] - 981s 853us/step - loss: 0.7628 - accuracy: 0.7766 - categorical_accuracy: 0.7057 - precision: 0.8709 - recall: 0.7051 - fmeasure: 0.7762 - val_loss: 0.4641 - val_accuracy: 0.8646 - val_categorical_accuracy: 0.7816 - val_precision: 0.9264 - val_recall: 0.8232 - val_fmeasure: 0.8713\n",
      "Epoch 2/5\n",
      "1149965/1149965 [==============================] - 990s 861us/step - loss: 0.4688 - accuracy: 0.8634 - categorical_accuracy: 0.8060 - precision: 0.9217 - recall: 0.8207 - fmeasure: 0.8678 - val_loss: 0.3346 - val_accuracy: 0.9038 - val_categorical_accuracy: 0.8249 - val_precision: 0.9449 - val_recall: 0.8701 - val_fmeasure: 0.9056\n",
      "Epoch 3/5\n",
      "1149965/1149965 [==============================] - 980s 852us/step - loss: 0.3569 - accuracy: 0.8981 - categorical_accuracy: 0.8386 - precision: 0.9353 - recall: 0.8664 - fmeasure: 0.8992 - val_loss: 0.2622 - val_accuracy: 0.9233 - val_categorical_accuracy: 0.8503 - val_precision: 0.9465 - val_recall: 0.9037 - val_fmeasure: 0.9244\n",
      "Epoch 4/5\n",
      "1149965/1149965 [==============================] - 980s 852us/step - loss: 0.2918 - accuracy: 0.9158 - categorical_accuracy: 0.8593 - precision: 0.9427 - recall: 0.8928 - fmeasure: 0.9169 - val_loss: 0.2163 - val_accuracy: 0.9360 - val_categorical_accuracy: 0.8673 - val_precision: 0.9527 - val_recall: 0.9231 - val_fmeasure: 0.9375\n",
      "Epoch 5/5\n",
      "1149965/1149965 [==============================] - 981s 853us/step - loss: 0.2521 - accuracy: 0.9268 - categorical_accuracy: 0.8738 - precision: 0.9480 - recall: 0.9087 - fmeasure: 0.9278 - val_loss: 0.1883 - val_accuracy: 0.9450 - val_categorical_accuracy: 0.8796 - val_precision: 0.9591 - val_recall: 0.9333 - val_fmeasure: 0.9459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27102400fc8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Deep Learning Model\n",
    "model_name = \"LSTM\"\n",
    "model = lstm()\n",
    "\n",
    "''' Training phrase '''\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.CategoricalAccuracy(),\n",
    "                       Evaluator.precision, Evaluator.recall, Evaluator.fmeasure])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T07:40:40.970327Z",
     "start_time": "2020-08-04T07:40:40.799469Z"
    }
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"./saved_model/lstm.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"./saved_model/lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
